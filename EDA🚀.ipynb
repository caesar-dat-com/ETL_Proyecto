{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA UPDATTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_column_letter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataframe_to_rows\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ruta\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ruta_archivo_entregable\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re  # Importar el módulo para trabajar con expresiones regulares\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from config import ruta\n",
    "from config import ruta_archivo_entregable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivos CSV:\n",
      "El archivo ACTIVIDADES 0002_GASCOL CENTRO (1).csv tiene 57 filas.\n",
      "Archivo procesado: ACTIVIDADES 0002_GASCOL CENTRO (1).csv\n",
      "El archivo ACTIVIDADES 0011_GASCOL SUR (3).csv tiene 310 filas.\n",
      "Archivo procesado: ACTIVIDADES 0011_GASCOL SUR (3).csv\n",
      "El archivo ACTIVIDADES 0021_G. LUX BOGOTÁ (1).csv tiene 693 filas.\n",
      "Archivo procesado: ACTIVIDADES 0021_G. LUX BOGOTÁ (1).csv\n",
      "El archivo ACTIVIDADES 0079_BELLO (1).csv tiene 718 filas.\n",
      "Archivo procesado: ACTIVIDADES 0079_BELLO (1).csv\n",
      "El archivo ACTIVIDADES 0092_MEDELLÍN (2).csv tiene 260 filas.\n",
      "Archivo procesado: ACTIVIDADES 0092_MEDELLÍN (2).csv\n",
      "El archivo ACTIVIDADES 0111_MALAMBO (1).csv tiene 875 filas.\n",
      "Archivo procesado: ACTIVIDADES 0111_MALAMBO (1).csv\n",
      "El archivo ACTIVIDADES 0198_POSTOBÓN PEREIRA (1).csv tiene 64 filas.\n",
      "Archivo procesado: ACTIVIDADES 0198_POSTOBÓN PEREIRA (1).csv\n",
      "El archivo ACTIVIDADES 0381_G. LUX MONTERÍA (1).csv tiene 64 filas.\n",
      "Archivo procesado: ACTIVIDADES 0381_G. LUX MONTERÍA (1).csv\n",
      "El archivo ACTIVIDADES 0385_NEIVA (1).csv tiene 478 filas.\n",
      "Archivo procesado: ACTIVIDADES 0385_NEIVA (1).csv\n",
      "El archivo ACTIVIDADES 0393_VILLAVICENCIO.csv tiene 22 filas.\n",
      "Archivo procesado: ACTIVIDADES 0393_VILLAVICENCIO.csv\n",
      "El archivo ACTIVIDADES 0395_G. LUX PASTO (1).csv tiene 146 filas.\n",
      "Archivo procesado: ACTIVIDADES 0395_G. LUX PASTO (1).csv\n",
      "El archivo ACTIVIDADES 0398_G. LUX VILLAVICENCIO (1).csv tiene 29 filas.\n",
      "Archivo procesado: ACTIVIDADES 0398_G. LUX VILLAVICENCIO (1).csv\n",
      "El archivo ACTIVIDADES 0410_YUMBO (2).csv tiene 939 filas.\n",
      "Archivo procesado: ACTIVIDADES 0410_YUMBO (2).csv\n",
      "El archivo ACTIVIDADES 0422_G. LUX PIEDECUESTA (1).csv tiene 681 filas.\n",
      "Archivo procesado: ACTIVIDADES 0422_G. LUX PIEDECUESTA (1).csv\n",
      "El archivo ACTIVIDADES 0438_CÚCUTA (1).csv tiene 200 filas.\n",
      "Archivo procesado: ACTIVIDADES 0438_CÚCUTA (1).csv\n",
      "El archivo ACTIVIDADES 0441_G. LUX DUITAMA (3).csv tiene 299 filas.\n",
      "Archivo procesado: ACTIVIDADES 0441_G. LUX DUITAMA (3).csv\n",
      "El archivo ACTIVIDADES 0445_NGB (1).csv tiene 55 filas.\n",
      "Archivo procesado: ACTIVIDADES 0445_NGB (1).csv\n",
      "El archivo ACTIVIDADES 0447_G. LUX VALLEDUPAR (2).csv tiene 135 filas.\n",
      "Archivo procesado: ACTIVIDADES 0447_G. LUX VALLEDUPAR (2).csv\n",
      "El archivo INSPECCIONES 0002_GASCOL CENTRO (1).csv tiene 92 filas.\n",
      "Archivo procesado: INSPECCIONES 0002_GASCOL CENTRO (1).csv\n",
      "El archivo INSPECCIONES 0011_GASCOL SUR (1).csv tiene 481 filas.\n",
      "Archivo procesado: INSPECCIONES 0011_GASCOL SUR (1).csv\n",
      "El archivo INSPECCIONES 0021_G. LUX BOGOTÁ (1).csv tiene 903 filas.\n",
      "Archivo procesado: INSPECCIONES 0021_G. LUX BOGOTÁ (1).csv\n",
      "El archivo INSPECCIONES 0079_BELLO (1).csv tiene 2133 filas.\n",
      "Archivo procesado: INSPECCIONES 0079_BELLO (1).csv\n",
      "El archivo INSPECCIONES 0092_MEDELLÍN (1).csv tiene 1541 filas.\n",
      "Archivo procesado: INSPECCIONES 0092_MEDELLÍN (1).csv\n",
      "El archivo INSPECCIONES 0111_MALAMBO (2).csv tiene 5813 filas.\n",
      "Archivo procesado: INSPECCIONES 0111_MALAMBO (2).csv\n",
      "El archivo INSPECCIONES 0198_POSTOBÓN PEREIRA (1).csv tiene 276 filas.\n",
      "Archivo procesado: INSPECCIONES 0198_POSTOBÓN PEREIRA (1).csv\n",
      "El archivo INSPECCIONES 0381_G. LUX MONTERÍA (1).csv tiene 1186 filas.\n",
      "Archivo procesado: INSPECCIONES 0381_G. LUX MONTERÍA (1).csv\n",
      "El archivo INSPECCIONES 0385_NEIVA (1).csv tiene 894 filas.\n",
      "Archivo procesado: INSPECCIONES 0385_NEIVA (1).csv\n",
      "El archivo INSPECCIONES 0393_VILLAVICENCIO.csv tiene 133 filas.\n",
      "Archivo procesado: INSPECCIONES 0393_VILLAVICENCIO.csv\n",
      "El archivo INSPECCIONES 0395_G. LUX PASTO (1).csv tiene 1109 filas.\n",
      "Archivo procesado: INSPECCIONES 0395_G. LUX PASTO (1).csv\n",
      "El archivo INSPECCIONES 0398_G. LUX VILLAVICENCIO (1).csv tiene 328 filas.\n",
      "Archivo procesado: INSPECCIONES 0398_G. LUX VILLAVICENCIO (1).csv\n",
      "El archivo INSPECCIONES 0410_YUMBO (4).csv tiene 3696 filas.\n",
      "Archivo procesado: INSPECCIONES 0410_YUMBO (4).csv\n",
      "El archivo INSPECCIONES 0422_G. LUX PIEDECUESTA (1).csv tiene 1773 filas.\n",
      "Archivo procesado: INSPECCIONES 0422_G. LUX PIEDECUESTA (1).csv\n",
      "El archivo INSPECCIONES 0438_CÚCUTA (1).csv tiene 712 filas.\n",
      "Archivo procesado: INSPECCIONES 0438_CÚCUTA (1).csv\n",
      "El archivo INSPECCIONES 0441_G. LUX DUITAMA (1).csv tiene 172 filas.\n",
      "Archivo procesado: INSPECCIONES 0441_G. LUX DUITAMA (1).csv\n",
      "El archivo INSPECCIONES 0445_NGB (1).csv tiene 536 filas.\n",
      "Archivo procesado: INSPECCIONES 0445_NGB (1).csv\n",
      "El archivo INSPECCIONES 0447_G. LUX VALLEDUPAR (2).csv tiene 3790 filas.\n",
      "Archivo procesado: INSPECCIONES 0447_G. LUX VALLEDUPAR (2).csv\n"
     ]
    }
   ],
   "source": [
    "# Listar todos los archivos en el directorio\n",
    "archivos = os.listdir(ruta)\n",
    "\n",
    "# Filtrar y procesar solo los archivos que terminan en .csv\n",
    "print(\"Procesando archivos CSV:\")\n",
    "for archivo in archivos:\n",
    "    if archivo.endswith('.csv'):\n",
    "        # Construir la ruta completa al archivo\n",
    "        archivo_completo = os.path.join(ruta, archivo)\n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(archivo_completo, encoding='utf-8')\n",
    "        # Mostrar la cantidad de filas\n",
    "        print(f\"El archivo {archivo} tiene {df.shape[0]} filas.\")\n",
    "        # Reemplazar puntos por comas en la columna 'Duración'\n",
    "        if 'Duración' in df.columns:\n",
    "            df['Duración'] = df['Duración'].astype(str).str.replace('.', ',')\n",
    "            # Guardar el archivo con los cambios\n",
    "            df.to_csv(archivo_completo, index=False, encoding='utf-8')\n",
    "            print(f\"Archivo procesado: {archivo}\")\n",
    "        else:\n",
    "            print(f\"La columna 'Duración' no existe en el archivo: {archivo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel creado con éxito en: C:\\Users\\cesar\\Desktop\\BIBLIOCASTIA\\TRANFORMACION CSV A XLSX\\Lista_Archivos_CSV_con_Codigos_y_Duraciones.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Listar todos los archivos en el directorio\n",
    "archivos = os.listdir(ruta)\n",
    "\n",
    "# Filtrar solo los archivos que terminan en .csv\n",
    "archivos_csv = [archivo for archivo in archivos if archivo.endswith('.csv')]\n",
    "\n",
    "# Función para extraer el código de cuatro dígitos\n",
    "def extraer_codigo(nombre_archivo):\n",
    "    match = re.search(r'\\d{4}', nombre_archivo)\n",
    "    return match.group(0) if match else 'Código no encontrado'\n",
    "\n",
    "# Función para calcular la sumatoria de la columna \"Duración\" en cada archivo CSV\n",
    "def sumar_duracion(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        # Sumar la columna \"Duración\", ignorando NaNs y valores no numéricos\n",
    "        suma_duracion = df['Duración'].dropna().sum()\n",
    "        return suma_duracion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Función para sumar \"Duración\" donde la columna \"Nombre\" tiene algún dato o usar \"codigo_personal_text\"\n",
    "def sumar_duracion_planeada(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Determinar qué columna usar (\"Nombre\" o \"codigo_personal_text\")\n",
    "        if 'Nombre' in df.columns and df['Nombre'].notna().any():\n",
    "            columna_usada = 'Nombre'\n",
    "        elif 'codigo_personal_text' in df.columns and df['codigo_personal_text'].notna().any():\n",
    "            columna_usada = 'codigo_personal_text'\n",
    "        else:\n",
    "            return 'Columna relevante no encontrada'\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        # Filtrar filas donde la columna seleccionada tiene algún dato no nulo y no vacío\n",
    "        df_filtrado = df[df[columna_usada].notna() & df[columna_usada].str.strip().astype(bool)]\n",
    "        # Sumar la \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "        suma_duracion_planeada = df_filtrado['Duración'].dropna().sum()\n",
    "        return suma_duracion_planeada\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Función para sumar \"Duración\" donde la columna \"Avance\" o \"Completado\" tiene algún dato\n",
    "def sumar_duracion_avance(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        # Intentar filtrar filas donde la columna \"Avance\" tiene algún dato no nulo y no vacío\n",
    "        if 'Avance' in df.columns:\n",
    "            df_filtrado = df[df['Avance'].notna() & df['Avance'].astype(str).str.strip().astype(bool)]\n",
    "        # Si no se encuentra la columna \"Avance\", usar la columna \"Completado\"\n",
    "        elif 'Completado' in df.columns:\n",
    "            df_filtrado = df[df['Completado'].notna() & df['Completado'].astype(str).str.strip().astype(bool)]\n",
    "        else:\n",
    "            return 'No se encontraron columnas relevantes (\"Avance\" o \"Completado\")'\n",
    "        # Sumar la \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "        suma_duracion_avance = df_filtrado['Duración'].dropna().sum()\n",
    "        return suma_duracion_avance\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def duracion_tipo_o_total(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        \n",
    "        # Si la columna 'Tipo' existe y tiene al menos un dato no nulo\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' tiene algún dato no nulo y no vacío\n",
    "            df_filtrado = df[df['Tipo'].notna() & df['Tipo'].str.strip().astype(bool)]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, sumar toda la columna \"Duración\"\n",
    "            suma_duracion = df['Duración'].dropna().sum()\n",
    "\n",
    "        return suma_duracion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "def duracion_tipo_preventivo_o_total(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        \n",
    "        # Si la columna 'Tipo' existe\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Preventivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Preventivo')]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Preventivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, sumar toda la columna \"Duración\"\n",
    "            suma_duracion_total = df['Duración'].dropna().sum()\n",
    "            return suma_duracion_total if suma_duracion_total > 0 else \"Sin datos de duración\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def duracion_tipo_preventivo_nombre_codigo(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Verificar las columnas necesarias\n",
    "        columna_nombre = 'Nombre' if 'Nombre' in df.columns else ('codigo_personal_text' if 'codigo_personal_text' in df.columns else None)\n",
    "\n",
    "        # Si no existe la columna 'Tipo', llamar a sumar_duracion_planeada\n",
    "        if 'Tipo' not in df.columns:\n",
    "            return sumar_duracion_planeada(nombre_archivo)\n",
    "\n",
    "        # Si existen las columnas 'Tipo' y alguna columna relevante de nombre o código\n",
    "        if columna_nombre:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Preventivo' y la otra columna tiene algún dato\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Preventivo') & df[columna_nombre].notna() & df[columna_nombre].str.strip().astype(bool)]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Preventivo' con datos relevantes en columna\"\n",
    "        \n",
    "        # Si la columna 'Tipo' existe pero no la columna relevante\n",
    "        return \"Columna relevante ('Nombre'/'codigo_personal_text') no encontrada\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error al procesar el archivo: {e}\"\n",
    "\n",
    "def duracion_tipo_preventivo_avance(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Si la columna 'Tipo' existe y es adecuada para el filtrado\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Preventivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Preventivo')]\n",
    "            # Calcular la suma de las duraciones para las filas filtradas\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            # Obtener la cantidad de filas filtradas que contienen 'Preventivo'\n",
    "            cantidad_filas_preventivo = len(df_filtrado)\n",
    "            # Verificar si hay datos para retornar\n",
    "            if cantidad_filas_preventivo > 0:\n",
    "                # Calcular promedio de duración por cada fila 'Preventivo'\n",
    "                promedio_duracion = suma_duracion / cantidad_filas_preventivo\n",
    "                return promedio_duracion\n",
    "            else:\n",
    "                return \"Sin datos 'Preventivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, retornar el resultado de otra función de manejo\n",
    "            return sumar_duracion_avance(nombre_archivo)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "    \n",
    "def duracion_tipo_predictivo_o_total(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        \n",
    "        # Si la columna 'Tipo' existe\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Predictivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Predictivo')]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Predictivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, marcar valor 0\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "def duracion_tipo_predictivo_nombre_codigo(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Verificar las columnas necesarias\n",
    "        columna_nombre = 'Nombre' if 'Nombre' in df.columns else ('codigo_personal_text' if 'codigo_personal_text' in df.columns else None)\n",
    "\n",
    "        # Si no existe la columna 'Tipo', retornar 0\n",
    "        if 'Tipo' not in df.columns:\n",
    "            return 0  # Cambio hecho aquí: retornar 0 directamente\n",
    "\n",
    "        # Si existen las columnas 'Tipo' y alguna columna relevante de nombre o código\n",
    "        if columna_nombre:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Predictivo' y la otra columna tiene algún dato\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Predictivo') & df[columna_nombre].notna() & df[columna_nombre].str.strip().astype(bool)]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Predictivo' con datos relevantes en columna\"\n",
    "        \n",
    "        # Si la columna 'Tipo' existe pero no la columna relevante\n",
    "        return \"Columna relevante ('Nombre'/'codigo_personal_text') no encontrada\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error al procesar el archivo: {e}\"\n",
    "    \n",
    "def duracion_tipo_predictivo_avance(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Verificar si la columna 'Tipo' existe y es adecuada para el filtrado\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Predictivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Predictivo')]\n",
    "            # Calcular la suma de las duraciones para las filas filtradas\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            # Obtener la cantidad de filas filtradas que contienen 'Predictivo'\n",
    "            cantidad_filas_predictivo = len(df_filtrado)\n",
    "            # Verificar si hay datos para retornar\n",
    "            if cantidad_filas_predictivo > 0:\n",
    "                # Calcular promedio de duración por cada fila 'Predictivo'\n",
    "                promedio_duracion = suma_duracion / cantidad_filas_predictivo\n",
    "                return promedio_duracion\n",
    "            else:\n",
    "                return \"Sin datos 'Predictivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, retornar cero\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "    \n",
    "def duracion_tipo_correctivo_o_total(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "        \n",
    "        # Si la columna 'Tipo' existe\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Correctivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Correctivo')]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Correctivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, marcar valor 0\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "def duracion_tipo_correctivo_nombre_codigo(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Verificar las columnas necesarias\n",
    "        columna_nombre = 'Nombre' if 'Nombre' in df.columns else ('codigo_personal_text' if 'codigo_personal_text' in df.columns else None)\n",
    "\n",
    "        # Si no existe la columna 'Tipo', retornar 0\n",
    "        if 'Tipo' not in df.columns:\n",
    "            return 0\n",
    "\n",
    "        # Si existen las columnas 'Tipo' y alguna columna relevante de nombre o código\n",
    "        if columna_nombre:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Correctivo' y la otra columna tiene algún dato\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Correctivo') & df[columna_nombre].notna() & df[columna_nombre].str.strip().astype(bool)]\n",
    "            # Sumar la columna \"Duración\" filtrada, ignorando NaNs y valores no numéricos\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            return suma_duracion if suma_duracion > 0 else \"Sin datos 'Correctivo' con datos relevantes en columna\"\n",
    "        \n",
    "        # Si la columna 'Tipo' existe pero no la columna relevante\n",
    "        return \"Columna relevante ('Nombre'/'codigo_personal_text') no encontrada\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error al procesar el archivo: {e}\"\n",
    "    \n",
    "def duracion_tipo_correctivo_avance(nombre_archivo):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(os.path.join(ruta, nombre_archivo))\n",
    "        # Reemplazar comas por puntos y convertir a flotante de forma segura\n",
    "        df['Duración'] = pd.to_numeric(df['Duración'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        # Verificar si la columna 'Tipo' existe y es adecuada para el filtrado\n",
    "        if 'Tipo' in df.columns:\n",
    "            # Filtrar filas donde la columna 'Tipo' es igual a 'Correctivo'\n",
    "            df_filtrado = df[df['Tipo'].notna() & (df['Tipo'] == 'Correctivo')]\n",
    "            # Calcular la suma de las duraciones para las filas filtradas\n",
    "            suma_duracion = df_filtrado['Duración'].dropna().sum()\n",
    "            # Obtener la cantidad de filas filtradas que contienen 'Correctivo'\n",
    "            cantidad_filas_correctivo = len(df_filtrado)\n",
    "            # Verificar si hay datos para retornar\n",
    "            if cantidad_filas_correctivo > 0:\n",
    "                # Calcular promedio de duración por cada fila 'Correctivo'\n",
    "                promedio_duracion = suma_duracion / cantidad_filas_correctivo\n",
    "                return promedio_duracion\n",
    "            else:\n",
    "                return \"Sin datos 'Correctivo'\"\n",
    "        else:\n",
    "            # Si la columna 'Tipo' no existe, retornar cero\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extraer el código único de cuatro dígitos de cada archivo\n",
    "codigos = [extraer_codigo(archivo) for archivo in archivos_csv]\n",
    "# Calcular la sumatoria de duración para cada archivo\n",
    "sumas_duracion = [sumar_duracion(archivo) for archivo in archivos_csv]\n",
    "# Calcular la sumatoria de duración planeada para cada archivo\n",
    "sumas_duracion_planeada = [sumar_duracion_planeada(archivo) for archivo in archivos_csv]\n",
    "# Calcular la sumatoria de duración con avance para cada archivo\n",
    "sumas_duracion_avance = [sumar_duracion_avance(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_o_total a cada archivo CSV\n",
    "duraciones_tipo_o_total = [duracion_tipo_o_total(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_preventivo_o_total a cada archivo CSV\n",
    "duraciones_tipo_preventivo_o_total = [duracion_tipo_preventivo_o_total(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_preventivo_nombre_codigo a cada archivo CSV\n",
    "duraciones_tipo_preventivo_nombre_codigo = [duracion_tipo_preventivo_nombre_codigo(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_preventivo_avance a cada archivo CSV\n",
    "duraciones_tipo_preventivo_avance = [duracion_tipo_preventivo_avance(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_mantenimiento a cada archivo CSV\n",
    "duraciones_tipo_predictivo_o_total = [duracion_tipo_predictivo_o_total(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_predictivo_nombre_codigo a cada archivo CSV\n",
    "duracion_tipo_predictivo_nombre_codigo = [duracion_tipo_predictivo_nombre_codigo(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_predictivo_avance a cada archivo CSV\n",
    "duracion_tipo_predictivo_avance = [duracion_tipo_predictivo_avance(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_correctivo_o_total a cada archivo CSV\n",
    "duraciones_tipo_correctivo_o_total = [duracion_tipo_correctivo_o_total(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_correctivo_nombre_codigo a cada archivo CSV\n",
    "duraciones_tipo_correctivo_nombre_codigo = [duracion_tipo_correctivo_nombre_codigo(archivo) for archivo in archivos_csv]\n",
    "# Aplicar la función duracion_tipo_correctivo_avance a cada archivo CSV\n",
    "duraciones_tipo_correctivo_avance = [duracion_tipo_correctivo_avance(archivo) for archivo in archivos_csv]\n",
    "\n",
    "\n",
    "# Crear un DataFrame con los nombres de archivo, códigos y sumas de duración\n",
    "df = pd.DataFrame({\n",
    "    'Nombres de Archivo CSV': archivos_csv,\n",
    "    'Código Único': codigos,\n",
    "    'Sumatoria de Duración': sumas_duracion,\n",
    "    'Sumatoria de Duración Planeada': sumas_duracion_planeada,\n",
    "    'Sumatoria de Duración con Avance': sumas_duracion_avance,\n",
    "    'Sumatoria de Duración (Tipo o Total)': duraciones_tipo_o_total,\n",
    "    'Sumatoria de Duración (Preventivo o Total)': duraciones_tipo_preventivo_o_total,\n",
    "    'Sumatoria de Duración (Preventivo con Nombre o Código)': duraciones_tipo_preventivo_nombre_codigo,\n",
    "    'Sumatoria de Duración (Preventivo con Avance)': duraciones_tipo_preventivo_avance,\n",
    "    'Sumatoria de Duración (predictivo o total)': duraciones_tipo_predictivo_o_total,\n",
    "    'Sumatoria de Duración (predictivo con Nombre o Código)': duracion_tipo_predictivo_nombre_codigo,\n",
    "    'Sumatoria de Duración (predictivo con Avance)': duracion_tipo_predictivo_avance,\n",
    "    'Sumatoria de Duración (correctivo o total)': duraciones_tipo_correctivo_o_total,\n",
    "    'Sumatoria de Duración (correctivo con Nombre o Código)': duraciones_tipo_correctivo_nombre_codigo,\n",
    "    'Sumatoria de Duración (correctivo con Avance)': duraciones_tipo_correctivo_avance\n",
    "    \n",
    "})\n",
    "\n",
    "# Convertir la columna 'Sumatoria de Duración con Avance' a tipo numérico\n",
    "df['Sumatoria de Duración con Avance'] = pd.to_numeric(df['Sumatoria de Duración con Avance'], errors='coerce')\n",
    "\n",
    "# Calcular el porcentaje y agregarlo como una nueva columna\n",
    "df['Porcentaje'] = (df['Sumatoria de Duración con Avance'] / df['Sumatoria de Duración'] * 100).map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "nombre_excel = \"Lista_Archivos_CSV_con_Codigos_y_Duraciones.xlsx\"\n",
    "ruta_completa_excel = os.path.join(ruta, nombre_excel)\n",
    "df.to_excel(ruta_completa_excel, index=False)\n",
    "\n",
    "print(f\"Archivo Excel creado con éxito en: {ruta_completa_excel}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam' con formato de color.\n"
     ]
    }
   ],
   "source": [
    "def unify_data(file_path):\n",
    "    # Carga el libro de trabajo existente\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb['Sheet1']  # Asume que los datos están en la hoja llamada 'Sheet1'\n",
    "\n",
    "    # Lee los datos desde la hoja específica\n",
    "    data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    \n",
    "    # Convierte las columnas de duración a numéricas, gestionando errores\n",
    "    for col in ['Sumatoria de Duración', 'Sumatoria de Duración Planeada', 'Sumatoria de Duración con Avance']:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Agrupa por 'Código Único' y agrega datos\n",
    "    unified_df = data.groupby('Código Único').agg({\n",
    "        'Sumatoria de Duración': 'sum',\n",
    "        'Sumatoria de Duración Planeada': 'sum',\n",
    "        'Sumatoria de Duración con Avance': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calcula el porcentaje y añade como nueva columna\n",
    "    unified_df['Porcentaje'] = (unified_df['Sumatoria de Duración con Avance'] / unified_df['Sumatoria de Duración'] * 100).map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    # Agrega una nueva hoja al libro con los datos unificados\n",
    "    new_ws = wb.create_sheet('indicadores_cam')\n",
    "    for r in dataframe_to_rows(unified_df, index=False, header=True):\n",
    "        new_ws.append(r)\n",
    "\n",
    "    # Aplica el formato de color gradiente\n",
    "    col_letter = get_column_letter(unified_df.columns.get_loc('Porcentaje') + 1)\n",
    "    for row in range(2, new_ws.max_row + 1):\n",
    "        cell = new_ws[f'{col_letter}{row}']\n",
    "        try:\n",
    "            percentage = float(cell.value.strip('%'))\n",
    "            green_intensity = int((percentage / 100) * 255)\n",
    "            red_intensity = 255 - green_intensity\n",
    "            hex_color = f\"{red_intensity:02X}{green_intensity:02X}00\"\n",
    "            cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "        except (ValueError, AttributeError):  # Maneja también AttributeError por si 'cell.value' es None\n",
    "            continue\n",
    "\n",
    "    # Guarda los cambios en el archivo de Excel existente\n",
    "    wb.save(file_path)\n",
    "\n",
    "# Especifica la ruta al archivo de Excel\n",
    "file_path = ruta_archivo_entregable\n",
    "\n",
    "# Llama a la función\n",
    "unify_data(file_path)\n",
    "\n",
    "print(\"Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam' con formato de color.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Preventivo', incluyendo el cálculo de porcentaje con formato de color.\n"
     ]
    }
   ],
   "source": [
    "def unify_data(file_path):\n",
    "    # Carga el libro de trabajo existente\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb['Sheet1']  # Asume que los datos están en la hoja llamada 'Sheet1'\n",
    "\n",
    "    # Lee los datos desde la hoja específica\n",
    "    data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    \n",
    "    # Convierte las columnas de duración a numéricas, gestionando errores\n",
    "    col_names = [\n",
    "        'Sumatoria de Duración (Preventivo o Total)', \n",
    "        'Sumatoria de Duración (Preventivo con Nombre o Código)', \n",
    "        'Sumatoria de Duración (Preventivo con Avance)'\n",
    "    ]\n",
    "    for col in col_names:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Agrupa por 'Código Único' y agrega datos\n",
    "    unified_df = data.groupby('Código Único').agg({\n",
    "        'Sumatoria de Duración (Preventivo o Total)': 'sum',\n",
    "        'Sumatoria de Duración (Preventivo con Nombre o Código)': 'sum',\n",
    "        'Sumatoria de Duración (Preventivo con Avance)': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calcula el porcentaje y añade como nueva columna\n",
    "    unified_df['Porcentaje'] = (unified_df['Sumatoria de Duración (Preventivo con Avance)'] / unified_df['Sumatoria de Duración (Preventivo o Total)'] * 100).map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    # Agrega una nueva hoja al libro con los datos unificados\n",
    "    new_ws = wb.create_sheet('indicadores_cam_Preventivo')\n",
    "    for r in dataframe_to_rows(unified_df, index=False, header=True):\n",
    "        new_ws.append(r)\n",
    "\n",
    "    # Aplica el formato de color gradiente a la columna 'Porcentaje'\n",
    "    col_letter = get_column_letter(unified_df.columns.get_loc('Porcentaje') + 1)\n",
    "    for row in range(2, new_ws.max_row + 1):\n",
    "        cell = new_ws[f'{col_letter}{row}']\n",
    "        try:\n",
    "            percentage = float(cell.value.strip('%'))\n",
    "            green_intensity = int((percentage / 100) * 255)\n",
    "            red_intensity = 255 - green_intensity\n",
    "            hex_color = f\"{red_intensity:02X}{green_intensity:02X}00\"\n",
    "            cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "        except (ValueError, AttributeError):  # Maneja también AttributeError por si 'cell.value' es None\n",
    "            continue\n",
    "\n",
    "    # Guarda los cambios en el archivo de Excel existente\n",
    "    wb.save(file_path)\n",
    "\n",
    "# Especifica la ruta al archivo de Excel\n",
    "file_path = ruta_archivo_entregable\n",
    "\n",
    "# Llama a la función\n",
    "unify_data(file_path)\n",
    "\n",
    "print(\"Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Preventivo', incluyendo el cálculo de porcentaje con formato de color.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Predictivo', incluyendo el cálculo de porcentaje con formato de color.\n"
     ]
    }
   ],
   "source": [
    "def unify_data(file_path):\n",
    "    # Carga el libro de trabajo existente\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb['Sheet1']  # Asume que los datos están en la hoja llamada 'Sheet1'\n",
    "\n",
    "    # Lee los datos desde la hoja específica\n",
    "    data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    \n",
    "    # Convierte las columnas de duración a numéricas, gestionando errores\n",
    "    col_names = [\n",
    "        'Sumatoria de Duración (predictivo o total)', \n",
    "        'Sumatoria de Duración (predictivo con Nombre o Código)', \n",
    "        'Sumatoria de Duración (predictivo con Avance)'\n",
    "    ]\n",
    "    for col in col_names:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Agrupa por 'Código Único' y agrega datos\n",
    "    unified_df = data.groupby('Código Único').agg({\n",
    "        'Sumatoria de Duración (predictivo o total)': 'sum',\n",
    "        'Sumatoria de Duración (predictivo con Nombre o Código)': 'sum',\n",
    "        'Sumatoria de Duración (predictivo con Avance)': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calcula el porcentaje y añade como nueva columna\n",
    "    unified_df['Porcentaje'] = (unified_df['Sumatoria de Duración (predictivo con Avance)'] / unified_df['Sumatoria de Duración (predictivo o total)'] * 100).map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    # Agrega una nueva hoja al libro con los datos unificados\n",
    "    new_ws = wb.create_sheet('indicadores_cam_Predictivo')\n",
    "    for r in dataframe_to_rows(unified_df, index=False, header=True):\n",
    "        new_ws.append(r)\n",
    "\n",
    "    # Aplica el formato de color gradiente a la columna 'Porcentaje'\n",
    "    col_letter = get_column_letter(unified_df.columns.get_loc('Porcentaje') + 1)\n",
    "    for row in range(2, new_ws.max_row + 1):\n",
    "        cell = new_ws[f'{col_letter}{row}']\n",
    "        try:\n",
    "            percentage = float(cell.value.strip('%'))\n",
    "            green_intensity = int((percentage / 100) * 255)\n",
    "            red_intensity = 255 - green_intensity\n",
    "            hex_color = f\"{red_intensity:02X}{green_intensity:02X}00\"\n",
    "            cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "        except (ValueError, AttributeError):  # Maneja también AttributeError por si 'cell.value' es None\n",
    "            continue\n",
    "\n",
    "    # Guarda los cambios en el archivo de Excel existente\n",
    "    wb.save(file_path)\n",
    "\n",
    "# Especifica la ruta al archivo de Excel\n",
    "file_path = ruta_archivo_entregable\n",
    "\n",
    "# Llama a la función\n",
    "unify_data(file_path)\n",
    "\n",
    "print(\"Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Predictivo', incluyendo el cálculo de porcentaje con formato de color.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Correctivo', incluyendo el cálculo de porcentaje con formato de color.\n"
     ]
    }
   ],
   "source": [
    "def unify_data(file_path):\n",
    "    # Carga el libro de trabajo existente\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb['Sheet1']  # Asume que los datos están en la hoja llamada 'Sheet1'\n",
    "\n",
    "    # Lee los datos desde la hoja específica\n",
    "    data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    \n",
    "    # Convierte las columnas de duración a numéricas, gestionando errores\n",
    "    col_names = [\n",
    "        'Sumatoria de Duración (correctivo o total)', \n",
    "        'Sumatoria de Duración (correctivo con Nombre o Código)', \n",
    "        'Sumatoria de Duración (correctivo con Avance)'\n",
    "    ]\n",
    "    for col in col_names:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Agrupa por 'Código Único' y agrega datos\n",
    "    unified_df = data.groupby('Código Único').agg({\n",
    "        'Sumatoria de Duración (correctivo o total)': 'sum',\n",
    "        'Sumatoria de Duración (correctivo con Nombre o Código)': 'sum',\n",
    "        'Sumatoria de Duración (correctivo con Avance)': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calcula el porcentaje y añade como nueva columna\n",
    "    unified_df['Porcentaje'] = (unified_df['Sumatoria de Duración (correctivo con Avance)'] / unified_df['Sumatoria de Duración (correctivo o total)'] * 100).map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    # Agrega una nueva hoja al libro con los datos unificados\n",
    "    new_ws = wb.create_sheet('indicadores_cam_Correctivo')\n",
    "    for r in dataframe_to_rows(unified_df, index=False, header=True):\n",
    "        new_ws.append(r)\n",
    "\n",
    "    # Aplica el formato de color gradiente a la columna 'Porcentaje'\n",
    "    col_letter = get_column_letter(unified_df.columns.get_loc('Porcentaje') + 1)\n",
    "    for row in range(2, new_ws.max_row + 1):\n",
    "        cell = new_ws[f'{col_letter}{row}']\n",
    "        try:\n",
    "            percentage = float(cell.value.strip('%'))\n",
    "            green_intensity = int((percentage / 100) * 255)\n",
    "            red_intensity = 255 - green_intensity\n",
    "            hex_color = f\"{red_intensity:02X}{green_intensity:02X}00\"\n",
    "            cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "        except (ValueError, AttributeError):  # Maneja también AttributeError por si 'cell.value' es None\n",
    "            continue\n",
    "\n",
    "    # Guarda los cambios en el archivo de Excel existente\n",
    "    wb.save(file_path)\n",
    "\n",
    "# Especifica la ruta al archivo de Excel\n",
    "file_path = ruta_archivo_entregable\n",
    "\n",
    "# Llama a la función\n",
    "unify_data(file_path)\n",
    "\n",
    "print(\"Los datos han sido unificados y añadidos a la nueva hoja 'indicadores_cam_Correctivo', incluyendo el cálculo de porcentaje con formato de color.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivos CSV:\n",
      "El archivo ACTIVIDADES 0002_GASCOL CENTRO.csv tiene 57 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0002_GASCOL CENTRO.csv\n",
      "El archivo ACTIVIDADES 0011_GASCOL SUR.csv tiene 310 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0011_GASCOL SUR.csv\n",
      "El archivo ACTIVIDADES 0021_G. LUX BOGOTÁ.csv tiene 693 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0021_G. LUX BOGOTÁ.csv\n",
      "El archivo ACTIVIDADES 0079_BELLO.csv tiene 718 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0079_BELLO.csv\n",
      "El archivo ACTIVIDADES 0092_MEDELLÍN.csv tiene 260 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0092_MEDELLÍN.csv\n",
      "El archivo ACTIVIDADES 0111_MALAMBO.csv tiene 875 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0111_MALAMBO.csv\n",
      "El archivo ACTIVIDADES 0198_POSTOBÓN PEREIRA.csv tiene 64 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0198_POSTOBÓN PEREIRA.csv\n",
      "El archivo ACTIVIDADES 0381_G. LUX MONTERÍA.csv tiene 64 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0381_G. LUX MONTERÍA.csv\n",
      "El archivo ACTIVIDADES 0385_NEIVA.csv tiene 478 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0385_NEIVA.csv\n",
      "El archivo ACTIVIDADES 0393_VILLAVICENCIO.csv tiene 22 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0393_VILLAVICENCIO.csv\n",
      "El archivo ACTIVIDADES 0395_G. LUX PASTO.csv tiene 146 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0395_G. LUX PASTO.csv\n",
      "El archivo ACTIVIDADES 0398_G. LUX VILLAVICENCIO.csv tiene 29 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0398_G. LUX VILLAVICENCIO.csv\n",
      "El archivo ACTIVIDADES 0410_YUMBO.csv tiene 939 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0410_YUMBO.csv\n",
      "El archivo ACTIVIDADES 0422_G. LUX PIEDECUESTA.csv tiene 681 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0422_G. LUX PIEDECUESTA.csv\n",
      "El archivo ACTIVIDADES 0438_CÚCUTA.csv tiene 200 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0438_CÚCUTA.csv\n",
      "El archivo ACTIVIDADES 0441_G. LUX DUITAMA.csv tiene 299 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0441_G. LUX DUITAMA.csv\n",
      "El archivo ACTIVIDADES 0445_NGB.csv tiene 55 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0445_NGB.csv\n",
      "El archivo ACTIVIDADES 0447_G. LUX VALLEDUPAR.csv tiene 135 filas.\n",
      "Archivo procesado y limpio: ACTIVIDADES 0447_G. LUX VALLEDUPAR.csv\n",
      "El archivo INSPECCIONES 0002_GASCOL CENTRO.csv tiene 92 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0002_GASCOL CENTRO.csv\n",
      "El archivo INSPECCIONES 0011_GASCOL SUR.csv tiene 481 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0011_GASCOL SUR.csv\n",
      "El archivo INSPECCIONES 0021_G. LUX BOGOTÁ.csv tiene 903 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0021_G. LUX BOGOTÁ.csv\n",
      "El archivo INSPECCIONES 0079_BELLO.csv tiene 2133 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0079_BELLO.csv\n",
      "El archivo INSPECCIONES 0092_MEDELLÍN.csv tiene 1541 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0092_MEDELLÍN.csv\n",
      "El archivo INSPECCIONES 0111_MALAMBO.csv tiene 5813 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0111_MALAMBO.csv\n",
      "El archivo INSPECCIONES 0198_POSTOBÓN PEREIRA.csv tiene 276 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0198_POSTOBÓN PEREIRA.csv\n",
      "El archivo INSPECCIONES 0381_G. LUX MONTERÍA.csv tiene 1186 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0381_G. LUX MONTERÍA.csv\n",
      "El archivo INSPECCIONES 0385_NEIVA.csv tiene 894 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0385_NEIVA.csv\n",
      "El archivo INSPECCIONES 0393_VILLAVICENCIO.csv tiene 133 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0393_VILLAVICENCIO.csv\n",
      "El archivo INSPECCIONES 0395_G. LUX PASTO.csv tiene 1109 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0395_G. LUX PASTO.csv\n",
      "El archivo INSPECCIONES 0398_G. LUX VILLAVICENCIO.csv tiene 328 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0398_G. LUX VILLAVICENCIO.csv\n",
      "El archivo INSPECCIONES 0410_YUMBO.csv tiene 3696 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0410_YUMBO.csv\n",
      "El archivo INSPECCIONES 0422_G. LUX PIEDECUESTA.csv tiene 1773 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0422_G. LUX PIEDECUESTA.csv\n",
      "El archivo INSPECCIONES 0438_CÚCUTA.csv tiene 712 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0438_CÚCUTA.csv\n",
      "El archivo INSPECCIONES 0441_G. LUX DUITAMA.csv tiene 172 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0441_G. LUX DUITAMA.csv\n",
      "El archivo INSPECCIONES 0445_NGB.csv tiene 536 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0445_NGB.csv\n",
      "El archivo INSPECCIONES 0447_G. LUX VALLEDUPAR.csv tiene 3790 filas.\n",
      "Archivo procesado y limpio: INSPECCIONES 0447_G. LUX VALLEDUPAR.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re  # Módulo para trabajar con expresiones regulares\n",
    "\n",
    "def limpiar_nombre(nombre):\n",
    "    # Elimina el texto dentro de los paréntesis incluyendo los paréntesis mismos\n",
    "    return re.sub(r\" ?\\([^)]+\\)\", \"\", nombre)\n",
    "\n",
    "# Listar todos los archivos en el directorio\n",
    "archivos = os.listdir(ruta)\n",
    "\n",
    "print(\"Procesando archivos CSV:\")\n",
    "for archivo in archivos:\n",
    "    if archivo.endswith('.csv'):\n",
    "        # Limpiar el nombre del archivo\n",
    "        nombre_limpio = limpiar_nombre(archivo)\n",
    "        # Construir la ruta completa al archivo original y al archivo limpio\n",
    "        archivo_completo = os.path.join(ruta, archivo)\n",
    "        archivo_limpio_completo = os.path.join(ruta, nombre_limpio)\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(archivo_completo, encoding='utf-8')\n",
    "        \n",
    "        # Mostrar la cantidad de filas y el nombre limpio\n",
    "        print(f\"El archivo {nombre_limpio} tiene {df.shape[0]} filas.\")\n",
    "        \n",
    "        # Reemplazar puntos por comas en la columna 'Duración' si existe\n",
    "        if 'Duración' in df.columns:\n",
    "            df['Duración'] = df['Duración'].astype(str).str.replace('.', ',')\n",
    "        \n",
    "        # Guardar el archivo con los cambios bajo el nuevo nombre limpio\n",
    "        df.to_csv(archivo_limpio_completo, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Si el nombre se ha cambiado, podemos optar por eliminar el archivo original\n",
    "        if nombre_limpio != archivo:\n",
    "            os.remove(archivo_completo)\n",
    "        \n",
    "        print(f\"Archivo procesado y limpio: {nombre_limpio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos .csv que contienen 'actividades': 18\n",
      "Cantidad de archivos .csv que contienen 'inspecciones': 18\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define la ruta donde se encuentran los archivos\n",
    "ruta = r\"C:\\Users\\cesar\\Desktop\\BIBLIOCASTIA\\TRANFORMACION CSV A XLSX\"\n",
    "\n",
    "# Función para contar archivos que contienen una palabra específica en el nombre\n",
    "def contar_archivos(ruta, palabra_clave):\n",
    "    contador = 0\n",
    "    # Listar todos los archivos en la ruta\n",
    "    for archivo in os.listdir(ruta):\n",
    "        # Checar si el archivo es un .csv y contiene la palabra clave\n",
    "        if archivo.endswith('.csv') and palabra_clave in archivo:\n",
    "            contador += 1\n",
    "    return contador\n",
    "\n",
    "# Contar archivos que contienen 'actividades' y 'inspecciones' en el nombre\n",
    "cantidad_actividades = contar_archivos(ruta, 'ACTIVIDADES')\n",
    "cantidad_inspecciones = contar_archivos(ruta, 'INSPECCIONES')\n",
    "\n",
    "print(f\"Cantidad de archivos .csv que contienen 'actividades': {cantidad_actividades}\")\n",
    "print(f\"Cantidad de archivos .csv que contienen 'inspecciones': {cantidad_inspecciones}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han unificado 18 archivos de 'actividades'.\n",
      "Se han unificado 18 archivos de 'inspecciones'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define la ruta donde se encuentran los archivos\n",
    "ruta = r\"C:\\Users\\cesar\\Desktop\\BIBLIOCASTIA\\TRANFORMACION CSV A XLSX\"\n",
    "\n",
    "# Función para unificar archivos que contienen una palabra específica en el nombre\n",
    "def unificar_archivos(ruta, palabra_clave, nombre_archivo_salida):\n",
    "    frames = []  # Lista para guardar los dataframes temporales\n",
    "    # Listar todos los archivos en la ruta\n",
    "    for archivo in os.listdir(ruta):\n",
    "        # Checar si el archivo es un .csv y contiene la palabra clave\n",
    "        if archivo.endswith('.csv') and palabra_clave in archivo.upper():\n",
    "            # Leer el archivo CSV y agregarlo a la lista de frames\n",
    "            df = pd.read_csv(os.path.join(ruta, archivo))\n",
    "            frames.append(df)\n",
    "    # Concatenar todos los dataframes en uno solo\n",
    "    df_concatenado = pd.concat(frames, ignore_index=True)\n",
    "    # Guardar el dataframe combinado en un nuevo archivo CSV\n",
    "    df_concatenado.to_csv(os.path.join(ruta, nombre_archivo_salida), index=False)\n",
    "    return len(frames)\n",
    "\n",
    "# Unificar archivos de actividades\n",
    "cantidad_archivos_actividades = unificar_archivos(ruta, 'ACTIVIDADES', 'actividades_unificadas.csv')\n",
    "print(f\"Se han unificado {cantidad_archivos_actividades} archivos de 'actividades'.\")\n",
    "\n",
    "# Unificar archivos de inspecciones\n",
    "cantidad_archivos_inspecciones = unificar_archivos(ruta, 'INSPECCIONES', 'inspecciones_unificadas.csv')\n",
    "print(f\"Se han unificado {cantidad_archivos_inspecciones} archivos de 'inspecciones'.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
